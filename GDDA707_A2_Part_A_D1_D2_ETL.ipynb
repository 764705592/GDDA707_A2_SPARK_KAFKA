{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397d6b02-ce9e-4f08-a070-2cfab4ed6a43",
   "metadata": {},
   "source": [
    "## DATASET 1 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60554e05-1dfe-408b-903c-32a92e6b9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Bitcoin Price Data (Dataset 1)\n",
    "bitcoin_historical_price_data= pd.read_csv('GDDA707_A2_Bitcoin_Historical_Price.csv',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a87d2f8-467b-4a72-8c30-d8de95162360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "Index(['timeOpen', 'timeClose', 'timeHigh', 'timeLow', 'name', 'open', 'high',\n",
      "       'low', 'close', 'volume', 'marketCap', 'timestamp'],\n",
      "      dtype='object')\n",
      "\n",
      "First few rows of the dataset:\n",
      "                   timeOpen                 timeClose  \\\n",
      "0  2025-01-05T00:00:00.000Z  2025-01-05T23:59:59.999Z   \n",
      "1  2025-01-04T00:00:00.000Z  2025-01-04T23:59:59.999Z   \n",
      "2  2025-01-03T00:00:00.000Z  2025-01-03T23:59:59.999Z   \n",
      "3  2025-01-02T00:00:00.000Z  2025-01-02T23:59:59.999Z   \n",
      "4  2025-01-01T00:00:00.000Z  2025-01-01T23:59:59.999Z   \n",
      "\n",
      "                   timeHigh                   timeLow  name          open  \\\n",
      "0  2025-01-05T23:03:00.000Z  2025-01-05T14:21:00.000Z  2781  98233.905777   \n",
      "1  2025-01-04T21:06:00.000Z  2025-01-04T15:51:00.000Z  2781  98106.993553   \n",
      "2  2025-01-03T19:22:00.000Z  2025-01-03T08:37:00.000Z  2781  96881.729023   \n",
      "3  2025-01-02T20:25:00.000Z  2025-01-02T00:19:00.000Z  2781  94416.286547   \n",
      "4  2025-01-01T21:25:00.000Z  2025-01-01T09:28:00.000Z  2781  93425.102136   \n",
      "\n",
      "           high           low         close        volume     marketCap  \\\n",
      "0  98813.308554  97291.764606  98314.959444  2.052525e+10  1.947190e+12   \n",
      "1  98734.428176  97562.975969  98236.229092  2.234261e+10  1.945654e+12   \n",
      "2  98956.917043  96034.614057  98107.428762  3.561139e+10  1.943223e+12   \n",
      "3  97739.816845  94201.570415  96886.878268  4.600956e+10  1.918730e+12   \n",
      "4  94929.864809  92788.127885  94419.757505  2.451989e+10  1.869850e+12   \n",
      "\n",
      "                  timestamp  \n",
      "0  2025-01-05T23:59:59.999Z  \n",
      "1  2025-01-04T23:59:59.999Z  \n",
      "2  2025-01-03T23:59:59.999Z  \n",
      "3  2025-01-02T23:59:59.999Z  \n",
      "4  2025-01-01T23:59:59.999Z  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset's columns\n",
    "print(\"Column names in the dataset:\")\n",
    "print(bitcoin_historical_price_data.columns)\n",
    "\n",
    "# Review the first few rows\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(bitcoin_historical_price_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "052f51f4-5ebf-4880-bca7-05781285751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data Head:\n",
      "                       Date    Open Price    High Price     Low Price  \\\n",
      "0 2025-01-05 00:00:00+00:00  98233.905777  98813.308554  97291.764606   \n",
      "1 2025-01-04 00:00:00+00:00  98106.993553  98734.428176  97562.975969   \n",
      "2 2025-01-03 00:00:00+00:00  96881.729023  98956.917043  96034.614057   \n",
      "3 2025-01-02 00:00:00+00:00  94416.286547  97739.816845  94201.570415   \n",
      "4 2025-01-01 00:00:00+00:00  93425.102136  94929.864809  92788.127885   \n",
      "\n",
      "    Close Price        Volume    Market Cap  \n",
      "0  98314.959444  2.052525e+10  1.947190e+12  \n",
      "1  98236.229092  2.234261e+10  1.945654e+12  \n",
      "2  98107.428762  3.561139e+10  1.943223e+12  \n",
      "3  96886.878268  4.600956e+10  1.918730e+12  \n",
      "4  94419.757505  2.451989e+10  1.869850e+12  \n",
      "\n",
      "Missing Values:\n",
      "Date           0\n",
      "Open Price     0\n",
      "High Price     0\n",
      "Low Price      0\n",
      "Close Price    0\n",
      "Volume         0\n",
      "Market Cap     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Clean and process the dataset\n",
    "\n",
    "# Define the date format explicitly\n",
    "date_format = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "\n",
    "# Convert relevant columns to datetime\n",
    "bitcoin_historical_price_data['timeOpen'] = pd.to_datetime(bitcoin_historical_price_data['timeOpen'], errors='coerce')\n",
    "bitcoin_historical_price_data['timeClose'] = pd.to_datetime(bitcoin_historical_price_data['timeClose'], errors='coerce')\n",
    "bitcoin_historical_price_data['timeHigh'] = pd.to_datetime(bitcoin_historical_price_data['timeHigh'], errors='coerce')\n",
    "bitcoin_historical_price_data['timeLow'] = pd.to_datetime(bitcoin_historical_price_data['timeLow'], errors='coerce')\n",
    "\n",
    "# Rename relevant columns for clarity\n",
    "processed_data = bitcoin_historical_price_data.rename(columns={\n",
    "    'timeOpen': 'Date',\n",
    "    'open': 'Open Price',\n",
    "    'high': 'High Price',\n",
    "    'low': 'Low Price',\n",
    "    'close': 'Close Price',\n",
    "    'volume': 'Volume',\n",
    "    'marketCap': 'Market Cap'\n",
    "})\n",
    "\n",
    "# Retain only relevant columns\n",
    "processed_data = processed_data[['Date', 'Open Price', 'High Price', 'Low Price', 'Close Price', 'Volume', 'Market Cap']]\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = processed_data.isnull().sum()\n",
    "\n",
    "# Drop rows with missing values (if necessary)\n",
    "processed_data = processed_data.dropna()\n",
    "\n",
    "# Ensure data types are consistent\n",
    "processed_data['Open Price'] = processed_data['Open Price'].astype(float)\n",
    "processed_data['High Price'] = processed_data['High Price'].astype(float)\n",
    "processed_data['Low Price'] = processed_data['Low Price'].astype(float)\n",
    "processed_data['Close Price'] = processed_data['Close Price'].astype(float)\n",
    "processed_data['Volume'] = processed_data['Volume'].astype(float)\n",
    "processed_data['Market Cap'] = processed_data['Market Cap'].astype(float)\n",
    "\n",
    "# Display summary information\n",
    "print(\"Processed Data Head:\")\n",
    "print(processed_data.head())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Export cleaned data to a new CSV (optional)\n",
    "processed_data.to_csv('GDDA707_A2_Processed_Bitcoin_Historical_Price.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "825d0801-194a-4334-89be-e81d8d3c3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " Date           0\n",
      "Open Price     0\n",
      "High Price     0\n",
      "Low Price      0\n",
      "Close Price    0\n",
      "Volume         0\n",
      "Market Cap     0\n",
      "dtype: int64\n",
      "Cleaned dataset saved to GDDA707_A2_Cleaned_Bitcoin_Historical_Price.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the processed dataset\n",
    "processed_data = pd.read_csv('GDDA707_A2_Processed_Bitcoin_Historical_Price.csv')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = processed_data.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n",
    "\n",
    "# Identify anomalies (e.g., negative values in numeric columns)\n",
    "numeric_columns = ['Open Price', 'High Price', 'Low Price', 'Close Price', 'Volume', 'Market Cap']\n",
    "for column in numeric_columns:\n",
    "    anomalies = processed_data[processed_data[column] < 0]\n",
    "    if not anomalies.empty:\n",
    "        print(f\"Anomalies found in {column}:\\n\", anomalies)\n",
    "\n",
    "# Handle missing values and anomalies (Example: Dropping rows with missing or invalid data)\n",
    "cleaned_data = processed_data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_data_path = 'GDDA707_A2_Cleaned_Bitcoin_Historical_Price.csv'\n",
    "cleaned_data.to_csv(cleaned_data_path, index=False)\n",
    "print(f\"Cleaned dataset saved to {cleaned_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65399d3-f111-46f3-bcad-74c450653552",
   "metadata": {},
   "source": [
    "## DATASET 2 and MERGE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c45176-609a-473d-8231-df6e9da41ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing Dataset 2 (Bitcoin Transaction Data)...\n",
      "Exporting processed Dataset 2 to GDDA707_A2_Processed_Bitcoin_Transaction_Data.csv...\n",
      "Processed Dataset 2 saved successfully to GDDA707_A2_Processed_Bitcoin_Transaction_Data.csv.\n",
      "Preview of processed Dataset 2:\n",
      "        Date  Input Total USD  Output Total USD  Transaction Fee USD\n",
      "0 2024-07-06     3.056420e+10      3.059348e+10          880864.1769\n",
      "1 2024-07-07     3.109948e+10      3.112518e+10          718883.0082\n",
      "2 2024-07-08     5.226770e+10      5.229549e+10          826843.1695\n",
      "3 2024-07-09     4.671503e+10      4.674232e+10          749427.1394\n",
      "4 2024-07-10     4.885546e+10      4.888006e+10          934674.8277\n",
      "Loading Cleaned Dataset 1 (Bitcoin Historical Price Data)...\n",
      "Filtering processed Dataset 2 to match the date range of Dataset 1...\n",
      "Merging Dataset 1 and processed Dataset 2...\n",
      "Exporting unified dataset to GDDA707_A2_Unified_Bitcoin_Dataset.csv...\n",
      "Unified dataset saved successfully to GDDA707_A2_Unified_Bitcoin_Dataset.csv.\n",
      "Preview of Unified Dataset:\n",
      "        Date    Open Price    High Price     Low Price   Close Price  \\\n",
      "0 2025-01-05  98233.905777  98813.308554  97291.764606  98314.959444   \n",
      "1 2025-01-04  98106.993553  98734.428176  97562.975969  98236.229092   \n",
      "2 2025-01-03  96881.729023  98956.917043  96034.614057  98107.428762   \n",
      "3 2025-01-02  94416.286547  97739.816845  94201.570415  96886.878268   \n",
      "4 2025-01-01  93425.102136  94929.864809  92788.127885  94419.757505   \n",
      "\n",
      "         Volume    Market Cap  Input Total USD  Output Total USD  \\\n",
      "0  2.052525e+10  1.947190e+12     4.420995e+10      4.425789e+10   \n",
      "1  2.234261e+10  1.945654e+12     4.654143e+10      4.658711e+10   \n",
      "2  3.561139e+10  1.943223e+12     6.534904e+10      6.539205e+10   \n",
      "3  4.600956e+10  1.918730e+12     5.991181e+10      5.996109e+10   \n",
      "4  2.451989e+10  1.869850e+12     5.053107e+10      5.057205e+10   \n",
      "\n",
      "   Transaction Fee USD  \n",
      "0          581040.0368  \n",
      "1          581838.0477  \n",
      "2          594336.1233  \n",
      "3          524187.7580  \n",
      "4          445790.4382  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File Paths\n",
    "transaction_data_path = 'GDDA707_A2_Bitcoin_Transaction_Data.csv'\n",
    "processed_transaction_data_path = 'GDDA707_A2_Processed_Bitcoin_Transaction_Data.csv'\n",
    "cleaned_price_data_path = 'GDDA707_A2_Cleaned_Bitcoin_Historical_Price.csv'\n",
    "unified_data_path = 'GDDA707_A2_Unified_Bitcoin_Dataset.csv'\n",
    "\n",
    "# PART A: TASK 2 - Load and Pre-process Dataset 2\n",
    "print(\"Loading and processing Dataset 2 (Bitcoin Transaction Data)...\")\n",
    "\n",
    "# Process Dataset 2 in chunks to handle large files\n",
    "chunksize = 1_000_000\n",
    "aggregated_data = []\n",
    "\n",
    "for chunk in pd.read_csv(transaction_data_path, chunksize=chunksize):\n",
    "    # Step 1: Convert 'time' to datetime and truncate to day-level\n",
    "    chunk['time'] = pd.to_datetime(chunk['time'], errors='coerce').dt.tz_localize(None).dt.floor('D')\n",
    "\n",
    "    # Drop rows with invalid or null dates\n",
    "    chunk = chunk.dropna(subset=['time'])\n",
    "\n",
    "    # Step 2: Rename columns for clarity and alignment\n",
    "    chunk = chunk.rename(columns={\n",
    "        'time': 'Date',\n",
    "        'input_total_usd': 'Input Total USD',\n",
    "        'output_total_usd': 'Output Total USD',\n",
    "        'fee_usd': 'Transaction Fee USD'\n",
    "    })\n",
    "\n",
    "    # Step 3: Group and aggregate data by 'Date'\n",
    "    aggregated = chunk.groupby('Date').agg({\n",
    "        'Input Total USD': 'sum',\n",
    "        'Output Total USD': 'sum',\n",
    "        'Transaction Fee USD': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Append aggregated data to the list\n",
    "    aggregated_data.append(aggregated)\n",
    "\n",
    "# Concatenate all aggregated chunks into one DataFrame\n",
    "transaction_data = pd.concat(aggregated_data, ignore_index=True)\n",
    "\n",
    "# Step 4: Drop duplicates (if any) by re-aggregating\n",
    "transaction_data = transaction_data.groupby('Date').agg({\n",
    "    'Input Total USD': 'sum',\n",
    "    'Output Total USD': 'sum',\n",
    "    'Transaction Fee USD': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Step 5: Export the processed Dataset 2\n",
    "print(f\"Exporting processed Dataset 2 to {processed_transaction_data_path}...\")\n",
    "transaction_data.to_csv(processed_transaction_data_path, index=False)\n",
    "\n",
    "print(f\"Processed Dataset 2 saved successfully to {processed_transaction_data_path}.\")\n",
    "print(f\"Preview of processed Dataset 2:\\n{transaction_data.head()}\")\n",
    "\n",
    "# PART A: TASK 3 - ETL Integration with Dataset 1\n",
    "print(\"Loading Cleaned Dataset 1 (Bitcoin Historical Price Data)...\")\n",
    "\n",
    "# Load Cleaned Dataset 1\n",
    "price_data = pd.read_csv(cleaned_price_data_path)\n",
    "price_data['Date'] = pd.to_datetime(price_data['Date']).dt.tz_localize(None)\n",
    "\n",
    "# Filter Transaction Data to match the Date range of Price Data\n",
    "print(\"Filtering processed Dataset 2 to match the date range of Dataset 1...\")\n",
    "transaction_data = transaction_data[\n",
    "    (transaction_data['Date'] >= price_data['Date'].min()) &\n",
    "    (transaction_data['Date'] <= price_data['Date'].max())\n",
    "]\n",
    "\n",
    "# Merge the cleaned datasets\n",
    "print(\"Merging Dataset 1 and processed Dataset 2...\")\n",
    "unified_data = pd.merge(\n",
    "    price_data,\n",
    "    transaction_data,\n",
    "    on='Date',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Check for duplicates after merging\n",
    "duplicates = unified_data[unified_data.duplicated(subset=['Date'], keep=False)]\n",
    "if not duplicates.empty:\n",
    "    print(\"Duplicates detected after merging:\")\n",
    "    print(duplicates)\n",
    "\n",
    "# Save the unified dataset\n",
    "print(f\"Exporting unified dataset to {unified_data_path}...\")\n",
    "unified_data.to_csv(unified_data_path, index=False)\n",
    "print(f\"Unified dataset saved successfully to {unified_data_path}.\")\n",
    "\n",
    "# Debugging outputs\n",
    "print(\"Preview of Unified Dataset:\")\n",
    "print(unified_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d338c4-c589-4563-8fcb-db8d329cd647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
